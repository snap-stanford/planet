{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "from collections import Counter \n",
    "from copy import deepcopy\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PlaNet knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import knowledge_graph\n",
    "from knowledge_graph.kg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kg_vocab():\n",
    "    kgid2x = {}\n",
    "    x2kgid = {}\n",
    "    for line in open('../data/graph/entities.dict'):\n",
    "        x, kgid = line.split()\n",
    "        kgid2x[kgid] = int(x)\n",
    "        x2kgid[int(x)] = kgid\n",
    "    relname2etype = {}\n",
    "    etype2relname = {}\n",
    "    for line in open('../data/graph/relations.dict'):\n",
    "        etype, name = line.split()\n",
    "        name = name[name.find('rel-name-'):][len('rel-name-'):]\n",
    "        relname2etype[name] = int(etype)\n",
    "        etype2relname[int(etype)] = name \n",
    "    return kgid2x, x2kgid, relname2etype, etype2relname\n",
    "\n",
    "kgid2x, x2kgid, relname2etype, etype2relname = load_kg_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PlaNet models for new clinical trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.demo_utils import load_model, load_model_and_data, model_inference, prepare_runner\n",
    "from gcn_models.utils import set_seed\n",
    "from gcn_models.evaluator import Evaluator\n",
    "set_seed(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load BERT embedder\n",
    "from utils.text_bert_features import TextBertFeatures\n",
    "bert_model = TextBertFeatures(\n",
    "    bert_model='microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext',\n",
    "    device='cpu' #'cuda:1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the new clinical trial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trial_data = pkl.load(open('small_data/trial_data_NCT02370680.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trial_1, new_trial_2 = new_trial_data\n",
    "new_trial_1, new_trial_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the feature of the new trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_feature(new_trial):\n",
    "    _new_emb = bert_model._embed(new_trial['arm_text'])\n",
    "    return np.concatenate([_new_emb, new_trial['trial_attribute_feats_vec']])\n",
    "\n",
    "new_emb_1 = get_trial_feature(new_trial_1)\n",
    "new_emb_2 = get_trial_feature(new_trial_2)\n",
    "print(new_emb_1.shape, new_emb_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the KG info of the new trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_edges(new_trial, the_x):\n",
    "    new_edges = []; new_etypes = []; seen = set()\n",
    "    for edge in new_trial_1['trial_arm_edges']:\n",
    "        h = the_x\n",
    "        t = kgid2x[edge['kg_id']]\n",
    "        r = relname2etype[edge['relation']]\n",
    "        new_edges.append([h,t])\n",
    "        new_etypes.append(r)\n",
    "        new_edges.append([t,h])\n",
    "        new_etypes.append(r+26)\n",
    "        seen.add(r)\n",
    "    for r in [21,22,23,24,25]:\n",
    "        if r not in seen:\n",
    "            new_edges.append([the_x,0])\n",
    "            new_etypes.append(r)\n",
    "            new_edges.append([0,the_x])\n",
    "            new_etypes.append(r+26)\n",
    "    new_edges = torch.tensor(new_edges).t()\n",
    "    new_etypes = torch.tensor(new_etypes)\n",
    "    print(new_edges.shape)\n",
    "    print(new_etypes.shape)\n",
    "    return new_edges, new_etypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for the AE task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the AE data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeidx2kgid = pkl.load(open('small_data/ae1017_idx2aename.pkl', 'rb'))\n",
    "aekgid2name = pkl.load(open('small_data/ae_kgid2name.pkl', 'rb'))\n",
    "aeidx2name = [aekgid2name[kgid] for kgid in aeidx2kgid]\n",
    "\n",
    "def predict_positive_ae(pred, threshold):\n",
    "    #pred: a list of length 1017\n",
    "    out = []\n",
    "    for idx, val in enumerate(pred):\n",
    "        if val > threshold:\n",
    "            out.append(aeidx2name[idx])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(ae_dataset, ae_tasks), \\\n",
    "    ae_encoder, ae_bert_encoder, \\\n",
    "    ae_model, ae_args, ae_runner \\\n",
    "    = load_model_and_data('../data/models/ae_model_shxo9bgw/ckpt.pt', device='cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the new trial to the inference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_dataset_bk = deepcopy(ae_dataset)\n",
    "ae_tasks_bk = deepcopy(ae_tasks)\n",
    "ae_args_bk = deepcopy(ae_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_trial_to_ae_dataset(dataset):\n",
    "    # Update the df\n",
    "    dataset.df = dataset.df[dataset.df['split']=='test'].head(1)\n",
    "    the_x = dataset.df.iloc[0]['x']\n",
    "    the_kgid = dataset.df.iloc[0]['kgid']\n",
    "    print('the_x', the_x, 'the_kgid', the_kgid)\n",
    "    \n",
    "    # Update the node features\n",
    "    _node_feats = deepcopy(dataset.node_feats)\n",
    "    pos = _node_feats[_node_feats['node_id'] == the_kgid].index[0]\n",
    "    _node_feats.at[pos, 'emb'] = new_emb_1\n",
    "    dataset.node_feats = _node_feats\n",
    "    \n",
    "    # Update the graph edges\n",
    "    _graph = deepcopy(dataset.graph)\n",
    "    new_edges, new_etypes = get_new_edges(new_trial_1, the_x)\n",
    "    \n",
    "    _edge_index = _graph.data.edge_index.clone()\n",
    "    columns_with_the_x = _edge_index.eq(the_x).any(dim=0)\n",
    "    _edge_index = _edge_index[:, ~columns_with_the_x]\n",
    "    _edge_index = torch.cat([_edge_index, new_edges], dim=1)\n",
    "    _graph.data.edge_index = _edge_index\n",
    "    \n",
    "    _edge_type = _graph.data.edge_type.clone()\n",
    "    _edge_type = _edge_type[~columns_with_the_x]\n",
    "    _edge_type = torch.cat([_edge_type, new_etypes], dim=0)\n",
    "    _graph.data.edge_type = _edge_type\n",
    "    \n",
    "    dataset.graph = _graph\n",
    "    \n",
    "    # Make the dataset ready for inference\n",
    "    x = dataset._get_data_x(dataset.df)\n",
    "    print('x', x)\n",
    "    tensors = [x]\n",
    "    tensors.extend([dataset.task_ys[0][0].repeat(len(x), 1)])\n",
    "    tensors.extend([dataset.sample_weight_masks[0][0].repeat(len(x), 1)])\n",
    "    dataset.datasets['test'] = TensorDataset(*tensors)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run inference for the new trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_dataset = add_new_trial_to_ae_dataset(ae_dataset)\n",
    "ae_args, ae_runner, ae_encoder \\\n",
    "    = prepare_runner(ae_args, ae_dataset, ae_encoder, ae_bert_encoder, ae_model, device='cpu')\n",
    "\n",
    "_, y_test_pred, _ = model_inference(ae_runner, mode='test') \n",
    "print ('y_test_pred.size()', y_test_pred.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted AEs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_positive_ae(y_test_pred[0], threshold=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for the Safety task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the safety data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sf_dataset, sf_tasks), \\\n",
    "    sf_encoder, sf_bert_encoder, \\\n",
    "    sf_model, sf_args, sf_runner \\\n",
    "    = load_model_and_data('../data/models/safety_model_1xekl810/ckpt.pt', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_dataset_bk = deepcopy(sf_dataset)\n",
    "sf_tasks_bk = deepcopy(sf_tasks)\n",
    "sf_args_bk = deepcopy(sf_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_trial_to_safety_dataset(dataset):\n",
    "    # Update the df\n",
    "    dataset.df = dataset.df[dataset.df['split']=='test'].head(1)\n",
    "    the_x = dataset.df.iloc[0]['x']\n",
    "    the_kgid = dataset.df.iloc[0]['kgid']\n",
    "    print('the_x', the_x, 'the_kgid', the_kgid)\n",
    "    \n",
    "    # Update the node features\n",
    "    _node_feats = deepcopy(dataset.node_feats)\n",
    "    pos = _node_feats[_node_feats['node_id'] == the_kgid].index[0]\n",
    "    _node_feats.at[pos, 'emb'] = new_emb_1\n",
    "    dataset.node_feats = _node_feats\n",
    "    \n",
    "    # Update the graph edges\n",
    "    _graph = deepcopy(dataset.graph)\n",
    "    new_edges, new_etypes = get_new_edges(new_trial_1, the_x)\n",
    "    \n",
    "    _edge_index = _graph.data.edge_index.clone()\n",
    "    columns_with_the_x = _edge_index.eq(the_x).any(dim=0)\n",
    "    _edge_index = _edge_index[:, ~columns_with_the_x]\n",
    "    _edge_index = torch.cat([_edge_index, new_edges], dim=1)\n",
    "    _graph.data.edge_index = _edge_index\n",
    "    \n",
    "    _edge_type = _graph.data.edge_type.clone()\n",
    "    _edge_type = _edge_type[~columns_with_the_x]\n",
    "    _edge_type = torch.cat([_edge_type, new_etypes], dim=0)\n",
    "    _graph.data.edge_type = _edge_type\n",
    "    \n",
    "    dataset.graph = _graph\n",
    "    \n",
    "    # Make the dataset ready for inference\n",
    "    x = dataset._get_data_x(dataset.df)\n",
    "    print('x', x)\n",
    "    tensors = [x]\n",
    "    tensors.extend([dataset.task_ys[0][0].repeat(len(x), 1)])\n",
    "    tensors.extend([dataset.sample_weight_masks[0][0].repeat(len(x), 1)])\n",
    "    dataset.datasets['test'] = TensorDataset(*tensors)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run inference for the new trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf_dataset = add_new_trial_to_safety_dataset(sf_dataset)\n",
    "sf_args, sf_runner, sf_encoder \\\n",
    "    = prepare_runner(sf_args, sf_dataset, sf_encoder, sf_bert_encoder, sf_model, device='cpu')\n",
    "\n",
    "_, y_test_pred, _ = model_inference(sf_runner, mode='test') \n",
    "print ('y_test_pred.size()', y_test_pred.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted probablity of safety concern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test_pred[0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for the Efficacy task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ef_dataset, ef_tasks), ef_encoder, ef_bert_encoder, ef_model, ef_args \\\n",
    "    = load_model('../data/models/efficacy_model_34l5ms9m/ckpt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_dataset_bk = deepcopy(ef_dataset)\n",
    "ef_tasks_bk = deepcopy(ef_tasks)\n",
    "ef_args_bk = deepcopy(ef_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add new trial to inference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_trial_to_efficacy_dataset(dataset):\n",
    "    # Update the df\n",
    "    _df = dataset.efficacy_df[dataset.efficacy_df['split']=='test'].head(1)\n",
    "    dataset.efficacy_df = _df\n",
    "    the_x1, the_x2 = _df.iloc[0]['x1'], _df.iloc[0]['x2']\n",
    "    the_kgid1, the_kgid2 = _df.iloc[0]['kgid1'], _df.iloc[0]['kgid2']\n",
    "    print('the_x1', the_x1, 'the_kgid1', the_kgid1, 'the_x2', the_x2, 'the_kgid2', the_kgid2)\n",
    "    \n",
    "    # Update the node features\n",
    "    _node_feats = deepcopy(dataset.node_feats)\n",
    "    pos = _node_feats[_node_feats['node_id'] == the_kgid1].index[0]\n",
    "    _node_feats.at[pos, 'emb'] = new_emb_1\n",
    "    pos = _node_feats[_node_feats['node_id'] == the_kgid2].index[0]\n",
    "    _node_feats.at[pos, 'emb'] = new_emb_2\n",
    "    dataset.node_feats = _node_feats\n",
    "    \n",
    "    # Update the graph edges\n",
    "    _graph = deepcopy(dataset.graph)\n",
    "    new_edges_1, new_etypes_1 = get_new_edges(new_trial_1, the_x1)\n",
    "    new_edges_2, new_etypes_2 = get_new_edges(new_trial_2, the_x2)\n",
    "    \n",
    "    _edge_index = _graph.data.edge_index.clone()\n",
    "    columns_with_the_x1 = _edge_index.eq(the_x1).any(dim=0)\n",
    "    _edge_index = _edge_index[:, ~columns_with_the_x1]\n",
    "    columns_with_the_x2 = _edge_index.eq(the_x2).any(dim=0)\n",
    "    _edge_index = _edge_index[:, ~columns_with_the_x2]\n",
    "    _edge_index = torch.cat([_edge_index, new_edges_1, new_edges_2], dim=1)\n",
    "    _graph.data.edge_index = _edge_index\n",
    "    \n",
    "    _edge_type = _graph.data.edge_type.clone()\n",
    "    _edge_type = _edge_type[~columns_with_the_x1]\n",
    "    _edge_type = _edge_type[~columns_with_the_x2]\n",
    "    _edge_type = torch.cat([_edge_type, new_etypes_1, new_etypes_2], dim=0)\n",
    "    _graph.data.edge_type = _edge_type\n",
    "    \n",
    "    dataset.graph = _graph\n",
    "    \n",
    "    # Make the dataset ready for inference\n",
    "    x = dataset._get_data_x(_df)\n",
    "    print('x', x)\n",
    "    tensors = [x]\n",
    "    tensors.extend([dataset.task_ys[0][0].repeat(len(x), 1)])\n",
    "    tensors.extend([dataset.sample_weight_masks[0][0].repeat(len(x), 1)])\n",
    "    dataset.datasets['test'] = TensorDataset(*tensors)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ef_dataset = add_new_trial_to_efficacy_dataset(ef_dataset)\n",
    "ef_args, ef_runner, ef_encoder \\\n",
    "    = prepare_runner(ef_args, ef_dataset, ef_encoder, ef_bert_encoder, ef_model, device='cpu')\n",
    "\n",
    "_, y_test_pred, _ = model_inference(ef_runner, mode='test') \n",
    "print ('y_test_pred.size()', y_test_pred.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted probability that trial arm 1 has better efficacy than trial arm 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_test_pred[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ctpy38]",
   "language": "python",
   "name": "conda-env-ctpy38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
